{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banana Navigation\n",
    "\n",
    "Banana Navigation is a Python implementation of Deep Reinforcement Learning methods to solve an environment where an agent has to collect as many yellow bananas as possible while avoiding the blue bananas in a large boxed squared environment.\n",
    "\n",
    "## The Environnement\n",
    "\n",
    "The **state** space has 37 dimensions and contains the agent's velocity, along with ray-based perception of objects around the agent's forward direction.<br>\n",
    "Given this information, the agent has to learn how to best select **actions**. Four discrete actions are available, corresponding to : <br> \n",
    "{0 - *move forward*, 1 - *move backward*, 2 - *turn left*, 3 - *turn right*} <br>\n",
    "A **reward** of +1 is provided for collecting a yellow banana, and a reward of -1 is provided for collecting a blue banana.<br>\n",
    "The **task** is episodic, and in order to **solve the environment**, your agent must get an average score of +13 over 100 consecutive episodes.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "You will need to install PyTorch, the ML-Agents toolkit, and a few more Python packages.\n",
    "\n",
    "1. Install the dependencies using the requirements file.\n",
    "    - cd to the directory where requirements.txt is located.\n",
    "    - activate your virtualenv.\n",
    "    - run: `pip install -r requirements.txt` in your shell.\n",
    "\n",
    "\n",
    "2. Download the environment from one of the links below.  You need only select the environment that matches your operating system:\n",
    "    - Linux: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana_Linux.zip)\n",
    "    - Mac OSX: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana.app.zip)\n",
    "    - Windows (32-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana_Windows_x86.zip)\n",
    "    - Windows (64-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana_Windows_x86_64.zip)\n",
    "\n",
    "    (_For AWS_) If you'd like to train the agent on AWS (and have not [enabled a virtual screen](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Training-on-Amazon-Web-Service.md)), then please use [this link](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana_Linux_NoVis.zip) to obtain the environment.\n",
    "\n",
    "3. Place the file in your working repository and unzip (or decompress) the file.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Follow the instructions in `Navigation.ipynb` to train an agent an watch it interact with the environment.  \n",
    "You will need to intanciate the `agent` and make it interact with the environment throught the use of the methods `act` and `step` as in the following example.\n",
    "\n",
    "\n",
    "```python\n",
    "from ressource.Agent_PER import Agent\n",
    "\n",
    "agent = Agent(state_size, action_size)\n",
    "\n",
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]           # get the current state\n",
    "score = 0                                         # initialize the score\n",
    "\n",
    "while True:\n",
    "    \n",
    "    action = agent.act(state)                     # select an action\n",
    "    \n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    \n",
    "    agent.step(state, action, reward, next_state, done) \n",
    "    \n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    \n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "```\n",
    "\n",
    "In order to load a pre-trained agent and to watch it interact with the environnment, use the following code:\n",
    "\n",
    "```python\n",
    "from ressource.Agent_PER import Agent\n",
    "\n",
    "def load_agent(modelname, path_model, use_dueling_net=True, use_DDQN=True):\n",
    "\n",
    "    checkpoint = torch.load(os.path.join(path_model, fr'{modelname}.pth'))\n",
    "    \n",
    "    agent = Agent_PER(state_size, action_size, use_dueling_net, use_DDQN)\n",
    "    agent.QNet_local.load_state_dict(checkpoint)\n",
    "    agent.QNet_target.load_state_dict(checkpoint)\n",
    "    \n",
    "    return agent\n",
    "\n",
    "agent = load_agent(modelname, path_model)\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = agent.act(state)                      # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))\n",
    "\n",
    "env.close()\n",
    "```\n",
    "\n",
    "## Contributing\n",
    "\n",
    "Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n",
    "\n",
    "## License\n",
    "[MIT](https://choosealicense.com/licenses/mit/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
